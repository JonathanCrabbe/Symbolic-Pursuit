{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div># 1. Building a Symbolic Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this short notebook, we detail how to use the *symbolic-pursuit* package that we developped to build a concise symbolic model for a black-box model. Here, the black-box model whe shall use is a *MLP* regressor model for a UCI dataset *wine quality red* <cite data-cite=\"2480681/TI5B4V8W\"></cite>.\n",
    "Note that our implementation of the meijer G-functions relies on the *pysymbolic* package<cite data-cite=\"2480681/IH83ZXGR\"></cite>.\n",
    "Let us simply start by importing the package we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_loader_UCI import data_loader, mixup  # dataset loader for the UCI dataset\n",
    "from symbolic_pursuit.models import SymbolicRegressor  # our symbolic model is an instance of this class \n",
    "from sklearn.neural_network import MLPRegressor # we use a MLP regressor as the black-box model\n",
    "from sklearn.metrics import mean_squared_error # we are going to assess the quality of the model based on the generalization MSE\n",
    "from sympy import init_printing # We use sympy to display mathematical expresssions \n",
    "import numpy as np # we use numpy to deal with arrays\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset into a trainig and a test subest. All the features are normalized to the range $[0,1]$ and the labels are divided by the average of their absolute value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data_loader(\"wine-quality-red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MLP regressor is fitted to the training subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we shall build the training set for the *symbolic model*. To capture the peculiarities of our black-box, this is done by using a mixup strategy on the original training set <cite data-cite=\"2480681/H82VI2CA\"></cite>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random = mixup(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use these as training points to fit a *symbolic model* to the black-box MLP regressor. \n",
    "This model is built by using a projection pursuit strategy <cite data-cite=\"2480681/AD298KCW\"></cite>. Note that the evaluation of Meijer G-functions is slow in the current Python implementations so this step might take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_model = SymbolicRegressor()\n",
    "symbolic_model.fit(model.predict, X_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the performance of the two models in terms of their MSE evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE score for the MLP Regressor: \", mean_squared_error(y_test, model.predict(X_test)))\n",
    "print(\"MSE score for the Symbolic Regressor: \", mean_squared_error(y_test, symbolic_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the performance of both model is comparable. The difference between the two model is the fact that the symbolic model is expressed in terms of analytic *Meijer G-functions* whose expression is short and concise. Let us display the epxression for the faithful model we just obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_model.get_expression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this model only involves one Bessel function.This model is expressed in terms of the following linear combinations of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_model.print_projections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2480681/AD298KCW": {
     "DOI": "10.1109/T-C.1974.224051",
     "abstract": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples. The algorithm seeks to find one-and two-dimensional linear projections of multivariate data that are relatively highly revealing.",
     "author": [
      {
       "family": "Friedman",
       "given": "J.H."
      },
      {
       "family": "Tukey",
       "given": "J.W."
      }
     ],
     "container-title": "IEEE Transactions on Computers",
     "id": "2480681/AD298KCW",
     "issue": "9",
     "issued": {
      "month": 9,
      "year": 1974
     },
     "note": "Conference Name: IEEE Transactions on Computers",
     "page": "881-890",
     "page-first": "881",
     "title": "A Projection Pursuit Algorithm for Exploratory Data Analysis",
     "type": "article-journal",
     "volume": "C-23"
    },
    "2480681/H82VI2CA": {
     "URL": "http://arxiv.org/abs/1710.09412",
     "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.",
     "accessed": {
      "day": 16,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Zhang",
       "given": "Hongyi"
      },
      {
       "family": "Cisse",
       "given": "Moustapha"
      },
      {
       "family": "Dauphin",
       "given": "Yann N."
      },
      {
       "family": "Lopez-Paz",
       "given": "David"
      }
     ],
     "container-title": "arXiv:1710.09412 [cs, stat]",
     "id": "2480681/H82VI2CA",
     "issued": {
      "day": 27,
      "month": 4,
      "year": 2018
     },
     "note": "arXiv: 1710.09412",
     "shortTitle": "mixup",
     "title": "mixup: Beyond Empirical Risk Minimization",
     "title-short": "mixup",
     "type": "article-journal"
    },
    "2480681/IH83ZXGR": {
     "URL": "http://papers.nips.cc/paper/9308-demystifying-black-box-models-with-symbolic-metamodels.pdf",
     "author": [
      {
       "family": "Alaa",
       "given": "Ahmed M."
      },
      {
       "family": "van der Schaar",
       "given": "Mihaela"
      }
     ],
     "container-title": "Advances in Neural Information Processing Systems 32",
     "editor": [
      {
       "family": "Wallach",
       "given": "H."
      },
      {
       "family": "Larochelle",
       "given": "H."
      },
      {
       "family": "Beygelzimer",
       "given": "A."
      },
      {
       "family": "Alché-Buc",
       "given": "F. d\\textquotesingle"
      },
      {
       "family": "Fox",
       "given": "E."
      },
      {
       "family": "Garnett",
       "given": "R."
      }
     ],
     "id": "2480681/IH83ZXGR",
     "issued": {
      "year": 2019
     },
     "page": "11304–11314",
     "page-first": "11304",
     "publisher": "Curran Associates, Inc.",
     "title": "Demystifying Black-box Models with Symbolic Metamodels",
     "type": "chapter"
    },
    "2480681/M3SSP879": {
     "DOI": "10.1145/2939672.2939785",
     "ISBN": "978-1-4503-4232-2",
     "URL": "http://dl.acm.org/citation.cfm?doid=2939672.2939785",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Chen",
       "given": "Tianqi"
      },
      {
       "family": "Guestrin",
       "given": "Carlos"
      }
     ],
     "container-title": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '16",
     "event": "the 22nd ACM SIGKDD International Conference",
     "event-place": "San Francisco, California, USA",
     "id": "2480681/M3SSP879",
     "issued": {
      "year": 2016
     },
     "language": "en",
     "page": "785-794",
     "page-first": "785",
     "publisher": "ACM Press",
     "publisher-place": "San Francisco, California, USA",
     "shortTitle": "XGBoost",
     "title": "XGBoost: A Scalable Tree Boosting System",
     "title-short": "XGBoost",
     "type": "paper-conference"
    },
    "2480681/TI5B4V8W": {
     "URL": "http://archive.ics.uci.edu/ml",
     "author": [
      {
       "family": "Dua",
       "given": "Dheeru"
      },
      {
       "family": "Graff",
       "given": "Casey"
      }
     ],
     "id": "2480681/TI5B4V8W",
     "issued": {
      "year": 2017
     },
     "publisher": "University of California, Irvine, School of Information and Computer Sciences",
     "title": "UCI Machine Learning Repository",
     "type": "book"
    },
    "2480681/W63LCK3U": {
     "DOI": "10.1016/j.dss.2009.05.016",
     "URL": "https://linkinghub.elsevier.com/retrieve/pii/S0167923609001377",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Cortez",
       "given": "Paulo"
      },
      {
       "family": "Cerdeira",
       "given": "António"
      },
      {
       "family": "Almeida",
       "given": "Fernando"
      },
      {
       "family": "Matos",
       "given": "Telmo"
      },
      {
       "family": "Reis",
       "given": "José"
      }
     ],
     "container-title": "Decision Support Systems",
     "container-title-short": "Decision Support Systems",
     "id": "2480681/W63LCK3U",
     "issue": "4",
     "issued": {
      "year": 2009
     },
     "journalAbbreviation": "Decision Support Systems",
     "language": "en",
     "page": "547-553",
     "page-first": "547",
     "title": "Modeling wine preferences by data mining from physicochemical properties",
     "type": "article-journal",
     "volume": "47"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
