{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building a Symbolic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this short notebook, we detail how to use the *symbolic-pursuit* package that we developped to build a concise symbolic model for a black-box model. Here, the black-box model whe shall use is a *SVM* classifier model for a UCI dataset *wine quality red* <cite data-cite=\"2480681/TI5B4V8W\"></cite>.\n",
    "Note that our implementation of the meijer G-functions relies on the *pysymbolic* package<cite data-cite=\"2480681/IH83ZXGR\"></cite>.\n",
    "Let us simply start by importing the package we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_loader_UCI import data_loader, mixup  # dataset loader for the UCI dataset\n",
    "from symbolic_pursuit.models import SymbolicClassifier  # our symbolic model is an instance of this class \n",
    "from sklearn.svm import SVC # we use a SVM classifier as the black-box model\n",
    "from sklearn.metrics import log_loss # we are going to assess the quality of the model based on the generalization log loss\n",
    "from sklearn.model_selection import train_test_split # we use this to split the dataset into a training and a test set\n",
    "from sklearn.datasets import load_breast_cancer # the classification dataset we are going to use for the experiment\n",
    "from sympy import init_printing # we use sympy to display mathematical expresssions \n",
    "import numpy as np # we use numpy to deal with arrays\n",
    "init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset into a trainig and a test subest. All the features are normalized to the range $[0,1]$ and the labels are divided by the average of their absolute value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SVM classifier is fitted to the training subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(probability=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we shall build the training set for the *symbolic model*. To capture the peculiarities of our black-box, this is done by using a mixup strategy on the original training set <cite data-cite=\"2480681/H82VI2CA\"></cite>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random = mixup(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use these as training points to fit a *symbolic model* to the black-box SVM. \n",
    "This model is built by using a projection pursuit strategy <cite data-cite=\"2480681/AD298KCW\"></cite>. Note that the evaluation of Meijer G-functions is slow in the current Python implementations so this step might take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Now working on term number  1 .\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  1 .\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.842140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 1\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  2 .\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 11.842142\n",
      "         Iterations: 0\n",
      "         Function evaluations: 3120\n",
      "         Gradient evaluations: 84\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  3 .\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.842140\n",
      "         Iterations: 1\n",
      "         Function evaluations: 418\n",
      "         Gradient evaluations: 11\n",
      "====================================================================================================\n",
      "The tree number  1  was selected as the best.\n",
      "====================================================================================================\n",
      "Backfitting complete.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The current model has the following expression:  σ(1.0*[ReLU(P1)]**0.25*exp(-0.25*I*pi)*besseli(0.5, 2.0*sqrt([ReLU(P1)])*exp_polar(I*pi/2)))\n",
      "The current value of the loss is:  11.84214034023116 .\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Now working on term number  2 .\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  1 .\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.842140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 1\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  2 .\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.842140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 1\n",
      "====================================================================================================\n",
      "Now working on hyperparameter tree number  3 .\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.842140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 38\n",
      "         Gradient evaluations: 1\n",
      "====================================================================================================\n",
      "The algorithm stopped because it was unable to find a term that significantly decreases the loss.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The final model has the following expression:\n",
      "σ(1.0*[ReLU(P1)]**0.25*exp(-0.25*I*pi)*besseli(0.5, 2.0*sqrt([ReLU(P1)])*exp_polar(I*pi/2)))\n",
      "P1 =  -1.27314538200194*X1 - 0.131854179607333*X10 - 0.679288735342555*X11 - 1.37590385443587*X12 - 1.20825766105207*X13 + 0.147945733672881*X14 + 0.512279699480107*X15 + 0.514298999505196*X16 - 0.665324759911238*X17 + 0.570333299643507*X18 - 1.25901020928724*X19 - 1.04514112522019*X2 + 0.177522171091293*X20 - 0.370458593221095*X21 + 0.955359316523103*X22 - 1.6111040771746*X23 + 1.32120418948573*X24 + 0.150838497061891*X25 - 1.09991320525515*X26 + 0.507018330862908*X27 - 0.718711608692359*X28 + 0.696644653939947*X29 + 1.67645724057484*X3 + 0.197346190253277*X30 - 0.259065810421908*X4 - 0.00640414241218379*X5 - 0.132460632585367*X6 - 0.592390875522769*X7 - 0.632141073153718*X8 + 1.17605718417642*X9\n",
      "The number of terms inside the expansion is 1 .\n",
      "The current loss is 11.84214034023116 .\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "symbolic_model = SymbolicClassifier()\n",
    "symbolic_model.fit(model.predict, X_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the performance of the two models in terms of their loss evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss for the SVM Classifier:  3.332752076499029\n",
      "Log-loss for the Symbolic Classifier:  14.542979365196159\n"
     ]
    }
   ],
   "source": [
    "print(\"Log-loss for the SVM Classifier: \", log_loss(y_test, model.predict(X_test)))\n",
    "print(\"Log-loss for the Symbolic Classifier: \", log_loss(y_test, symbolic_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the performance of both model is comparable. The difference between the two model is the fact that the faithful model is expressed in terms of analytic *Meijer G-functions* whose expression is short and concise. Let us display the epxression for the faithful model we just obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAAmCAYAAADz0CO2AAAACXBIWXMAAA7EAAAOxAGVKw4bAAATRklEQVR4Ae2d65UctRLHxz4bwNpEcE0Gxo7AJgMeERgygONvfPOBDMARXHAGmAhsnAEQAb6bge//p1HJarXUrZ7u6enZUZ3Tq7dUVaqHpFbP3vnw4cOuQeNA40DjwLE48MMPP3xD3wp/OdYYrd/GgS1yQDJ/LbxeKvyyhN/dUkHLbxxoHGgcmMsBGZ/v1Me3zQHP5WRrf44ckNzfCO+fFf5Zwr854RJnWn7jQOPALA7I8DxVB8/1PJnVUWvcOHBCDgw50Bq01P616v1X4W+5+s0J57jS8hoHGgdmcUAGh2M4jM4TxdkNNGgcOFcOzF5ESgd+EvEPFLpXMzEj7rR3wjE7WrzEAQkPx4qf6PmXUOnvS3UtX3V+VBxj/EDP33q+V54zyAofKs0u6YUe8tg17ZS/6ntDjXcSuvy4nyr8FrpvG4gut+pXWHwXdk40i46fhW/PgJ4TDZeMq+bvzqnpFw7YQY6l/6N4WJhenRqxNv72OSCBwfgEx6v0F3p+01M0sCrDAfMuBOe7U4hR/kPPZ6QF9/V84R/Sr1Sn2B8VlgaNd0q6OKJ6tTRNW+hPfGWBxdx+ugV85uIgejCe7GJObsjn0tLa13NA840MM/c7xdnJOlCcDQOLMmzY+yh8p7KiDVPZ33rQ+5d6Qr27SjRoHBjjALve362SBAnngSNml1sCBDgGdrwP1cYJtS9AEHHK95QfhNKXrRGcjC7Ri8K6BcoahK48BkaGRdVtoY8FJU+Dy+PAO5GcLiavJdvk/eLDF4R6amwYdrBjO5sTvjyhmkSxBAtHi+NkxRdDOEKOM5N47HDt+CXOY2WIM7KypPnxkreVruNxrK5n8ZX5ZSc8+rqirsfT1vL0sAtmB9PggjigOWezwesidr0ByNeDXeQBUie9z838VTucOk94tdGOozOMalkdDpjTTB0lTpnjmCxI2FLBxDADb/eB+8unK3/5NPXDO+OozrGiJ6FL9HKUBS8eKx5WzoqDD0f2xidFO/CZ6qC8Wwec723a5UPPrVhQbF1wtoaf9A0ny+kd8vxUT7wQ+0pldjqITk8BnDonK+6Ie1UnLCK4BPO1x/YZxPn4xQSiGWPLhK56AQkGa0yOiLMGUmWszFj1IXg4x1jglNXbCZNnK0HiY4DQxU6Wo0reK7tx/Pg4oc/HOlq4nMVECsek63PRCh8+6OFY68YPjqF/5uMoNfLheEZeVI/klgHjxJHb2QPzIyIeKUQvAijd7NiJ7Jh4P8eGhTmsiWisGz3YS+Y7tdfYKdNX6jhnXdOv6mDz0H3n2BdzwuoQg8HNWYwKuxq+i0qdLLdrMUCpgVe2MzQ4Aoiz94l2cSU2ihjulCE0rwa1T8cBT5wCONuYrj+lcZrQxg6FOPSxm+PSUairOKsiWxHRH32Fl/lK75SGDtpBYw+Un+IFnxjPgPEZO3ZmVjYaqn+OUeAf7Tvv65SGp7zjgNYc3FdmjAvpKvB9vlYY+KE448c4GE85+ovzq8aYUWk1ujyOvD9CvjmKd/xUiEI6Q68QhWeeMAA7wiHaVE79x3pMZ5A9ePmjytbkI7gin9d6svqt/ACqSz2TNdoByGVqM/Ylmb+qW2NzMi2rs56rZm5B0ezYieyY5nyODaueeKuo8cJpleURxvlxPK5Tiqu+6T5+4HXHCasQReZSRecKdakzy1c7rl1jXJxTUoiC/amQVX+1IVBdcwT8liZGu8MApVFW67dTpvxqSMZhFWM3dnt9qAz8v1SIwmPwiPeMjPKglfKdwuBsSEfA7eAi3moX0w9ePWetPJz9Pwqzc6T8sTl8pvbxLeUIvWzU5o85jYH0qMEUPiwsgpOxDpTPkUy8mLBxmGOLW/XRUP2xAKo5NmT+bqIxVqNL4zq5UYjDDe+ZPD5GI3L0kx5zTJafDalLgUJ0ZlCWsx0sm+kWocJlUC5UDs87P+WnPPTLdLunXymaqr+IzUn7tbTH8anCGpmyZi5Um1iPmx2baMfEv6VtWGd+ahLC4eDfc1bbmlv0yLjTlys1cAqhDAwfip8aJWWVQe0xsuxenAOmpuKs4klzvFh0cNRNQe3YcQJ23r5P6a/K7Io3t8umbP9DHxZRe8cApUcV3rcxAzNU373XtDHiUOPBp7fQEOencejyeaVxMN7gQn9mgKvnUP0zNxiG7/SUFgsehTCX4Jzb+bLjKoL6B8/wLaxPv1eIkf5KD4b3Rg9g/Q/2ua/a/6s+4VeJZ70Gqg8fVqdLYzJX8IXFQEeGlY4dL3HjSQ//OEPtnGwqr5r+uP2CcXR9UL79WMw7i8EAooEFGTKNzbgXCjIRX28xm5MZgix2wWGhVKhTzBaOpsfNjuW51LFj4tfRbFh++OFc4dNxpH4+7VUqc8sruxpZLw30RgXu9AonjBF0uzPFUQJXUGqZyadtTvkZBEPPLsgMbaZ5L8sMSnDqSQ0T7il9Jl24pO0ye0qSq6w8xs3RGVe/P0ArK2obM26Txo3+El5mqDkSc+DHnDKHHLH9o2fUCe9HcMYozLPGQ0bckSnlSoMTSmW7TPLgF8bWjl8Vde+cHZ6Ks1t4T6YHdocch8+dV+uvJnQ4q6KbV429Bl3MLztWFgEodbxrREZwQgC8MVlwGQN/TK5KMjPQdNEi8K0xTCzAqJte3mMeWGCPvZIIsqj6MRxqc+I+LA4eKX5WVhPa3DU7ludWx46hD6p2TBuWx6I+l9c7Ts8UYtvQtTny4fREfT24W49DsaYJW1rBjGmpPK1vaQi1XYrluVAIYySZPHZyNcreaZ8kHF7qZ8yx7lTHaCgaOdW5Vv9ZnFTmBE5htjzByya6hNdjX7+IS9JfLyk8mBtOFYyuXp04Q/Vw1n8pRBBxrByZmjOlKrQ/0nOfhAeOvBFWnIo9T9XOyYVCHM5z+tPjdhwKccSrgcY7BV3MK7yHj47uiGDm41fSKsc5c2oAb8egWpbHOppZjpzXyDh1cLQl2kr5hl5Jbp1sqVKp3NoPhsKL10rMzxxodkzcEy+PYsfUL3NdbcPmTKRvG9s2J78z+zQ9eXg1pyMxwpQl3tGkXToHlGYOpFGg3upRY+GAX1KmeOwAXFcel+dKcDkMYJUydDkFBxHvQmhTAucYVVgSKNqxui85RnAfakt7A+jP4iUa4SV9sWOs7c/6TUPaw8eqfjRecdesMvDtHCEqr5NOByetOjjiKlBdZG3K/Nb2uypdogPj0ZNfkFVZZ2WdpgcIQpar5nGgj6WK7JOzYn+iq/SKCjoAM1D7VPRXbY9hc6IRXJSjxs5cpBUq0s2OHd+OTbJhzJmXn8l2RO1imWVuizJaIRtUsfb3ryoblKrZ6gDDksKQY07rurQINSWEWRyNo3CP9TjHo5Afg+85KOXBFHYV4SKY8nBY7Kx6ht7XV1G14WJ8due9senEA99xcsSaA5y4HTPmyl2e2hv9PYOqMnBgdc6lnR5NxU7LBRjLVXeeZVSGS0TvpPkd7u12lXreQFRvAagydnS8tmBhGn52VPEsqD7yh4F6oQedhu875ZfkmmIHqmPOMWcLrFoxVHvGQmeR76E+DrY54DjS907l8AxbcjCoD9Nj+mt2LOKk+LGkHZtkwzT2bDuiPpBzdMQ2ZhF19VH1gz+hwfVVfbPBmqaAuUrh3WWuMMmDScAzkNxHnRFAkEsOlbFxcLRxqwuF5OGoSspkDOwZLrXpgO8L49DbnXcqdo9ikyJnXGoWJUY/R3XxcRj0IHA4+sCXdJCJafCh302D5//U+d00TQsjZ7LcWbiJb+hMcLxK845z8Pe+VR8Hh5HkAbKnTvui3l9zjr2Cygx0lfFqF5hDstuxOeoT/UXX0eGx/pfaBWuoZsfE+2PasWobJjyQl1l2xPfxUv2wGVzKDn8y1wkPORZTSjseRijHAIPCCqFDoNIcv6KkrEBSJYIpAJeiWMUCtI8/f3GZ0R/n7FS/Y7ii8p3KbNVsjrHosFUXJX8Tt0/i8KJDU1JuSTOonUWIFS4csmAB763DIfO7dZqWxM9k+V3SKXoSTjokozg4nLDJdVI9JDkqRzZ431Yjs9bw2keGbILV7YQaB93mnkfAt1Ohmxjqv2dz1Cf8Qc6hiYVJaj+UtQfVpXxssW3Vh8Jmx/bcObYdm2LDZtkRyQbyzYLiGaQpzavOoixRpxLm7YSFhG2pTfjjcU0pYVQtoDA9JdA45iwsjPtj1Y6BGT0yixo9VHzIAaOMlGOEOA4H3u6D7F+MB4ZkLkD/VOM3d8yttz9kfrdO05L49WRZuoDuoSupw0KeszoWIYT8pQ49Kl42qrHcwllhjQPeqd4km6P6Ts8VYod+V/iNnpKtwKjG7/4OJTbLY41r9svCuP9D5Lw393GH0Kp0s2N7phzC35idfJfOvMFTAHlawgnvrlx38/4wyeZw457MMTsliAtycQkMAgXkdpxWlhqVfYs9Qyw+GGocFATIjbMv2R/7dhRV7YYM09gnFeCd45GNt4vor+JXaHh4hPmZskA6fKT5Lc8Fz/mUTuhhQJbNyON0Y0AOTS/j/DjOcaxdruJy0tCJUtzOxhrrP7TROBjG8B05BcpzuCscmvPJNkf92RcVGM6ObvtxzUgbHWRPBo1jtipnX6ys2bHJnM02QNaG5CRtNKVup63mde5FvbQ/8wc3dzslhyU4Z3+UaQrS7nvITFkuy5xjbsdpu1EzDjsxxYgoMlZ17Hg6Hs+OfLPOzrdh1WPgjpmj8SzfhcqH/rEVETiOGSejn/7WAIzdLIOzBpIaY+r8roTWJoYZlGVhmDP2pjc5AuA1R9ZcjuLWOHpQK4821lD/YUz1j0N6rDDdAeMMxwCcDrE5nFaxYDZdi8fhVdeLOOPAuPXd7NiBDJzQbIoN25odMX/w11VCcFGBJLiU/U8PjjUc2SjO+1pWy1z8cEfJCqnLtv2Jnlr4mopq+y7T4E2cpzowHyVmPBTLtVXowI/P+X18KcCX7i+d5MZRHvVx3OHzGuVx1A1OlAWDoTxwII8foyhOsMoB2geeuZz+H6Mhp7z92uWc4hwmTcAnuxBJ6p06OXV+T43vmuM7h+XlMzcuin4TFZjiR1kfo16OY1lGFvmt87GTnp3q2DHxJx97zMfoTyU4UnTLdBS5BT9+Rcx9NqaQvCVtDjtg0+Mg+xoHPr5VGPNKWQdBs2N7ts2xY8x7DUyxYVuzI0bje+eEJXwgiALYKu4P5cFEfsvVHd0goHpQ0FhJlXQAM/jhBZQLYOea/ZzIlUZ/1IaxWdU+JFtplJN3N+HISHGUFcX8XKECV88UlVX7Tg/9hB2s0rHDhGBezIOfw1HljMPqHbrJc+MrZKyOMirNrWRexHPERBnt+PEKLrHUAO3Arwfqo0O/KvCbum/0OPp6DQoZvp/BOUyawnN3ySDJ31QSPujZefqy87sphI+MjPhQkmXe5X7vhzcdpW4MpFkQZsHzOD5+tn7QD4tn2/pMdMPp11AllaF71MudVIVxhM+iNsf3h13hvXC8sHiuvFpdVtU+eN41O/bRjk62Y56HR7Fh6ntrdgQ6gZs7Hz4c/DvV+y4m/BUjWIXiYMMqdELzs64qmjlKZxERjMypCBIOGGMWWL33HMq72Dk61XwcY1zNI/LG+92ga4qj7PcU4ix7oHx2nSw4nYwqxFHST7FN3Inqs9jkKwUW5ZuEiCaMMgsONh7wqdoJq+7F6oho34QdEx5nbcOEPyfFbMDu3d2kptxOpFBc26mcmkJW/ghAg9vLAeY3OBYpPUeu4ZRHaXaCLIgxZgbsEjnlMeA0acrvebPLrtkJW/+rh6KXBQYLE7vlik5uRS9X58cBA27Fjp27DWMDxEnPIhezDpjHy2siZmPgMHwnNVIaH6P7VOGk4+7Lm7HzptjP76Tf+1YbnNGc3/N+o/bXXsa2zEAcCXhyLG5H3lvGdzO4iWcnt2Nevs7dhnEC406prjYzu5eBCDsTFN9utZ6CasYPO6RTINDGXIcDMlbFhZbK2LWGC4iGkfLn7Art6Psr9Yex3iSIRvtcidOBzR6db5J5e6RObcfO2oZJ/tgIcQfJnUaufRz9LwMLCd5HgsRFgWi+EcG8f7KjsFXp9+Myfu+9tPL4t5NcfMIwNWgcmMwByQ/yjSM+5SKzFm8MIM64eFFtoKNmx05kxzRf2M5zt2HsggG3aF31YtZ+3Pa3caBx4LZywBtJviTo7bJvK82NrsaBKRyQbrAAfKTQncKsvROegmur2zjQOHB+HPhVKPO+tZ2onN/cNYzX4QCva8IPwzQnvA7T2yiNAxfBATlfjqTdBa+LILgR2TgwgQPSD/dtvMJX1qw5YeNECxsHGgcW4YAMDBfC+BLg4u59LMLA1slt5gCfVnUuPzYnfJunu9HWOHA6DmBo+JW6Bo0DjQPigBal7IL5ZbvOlwPNCTfxaBxoHFicA97QvPeGZ/H+W4eNA+fEAenBA+HLLrj3eWhzwuc0kw3XxoHz4gAGh89J2rH0ec1bw3ZBDkj++S6Yn3R9pnjv89DmhBdkduuqcaBx4CMHZHC4pMU3w/x7RHYCDRoHLpED/LgIn+2Fy1gxE5oTjrnR4o0DjQOLcsCv/HHE7AYaNA5cFAck/8g9DrjzHjhmwv8BCruF37b4TY8AAAAASUVORK5CYII=\n",
      "text/latex": [
       "$\\displaystyle 1.0 [ReLU(P1)]^{0.25} e^{- 0.25 i \\pi} I_{0.5}\\left(2.0 \\sqrt{[ReLU(P1)]} e^{\\frac{i \\pi}{2}}\\right)$"
      ],
      "text/plain": [
       "                                     ⎛                         ⅈ⋅π⎞\n",
       "                                     ⎜                         ───⎟\n",
       "              0.25  -0.25⋅ⅈ⋅π        ⎜           ____________   2 ⎟\n",
       "1.0⋅[ReLU(P1)]    ⋅ℯ         ⋅besseli⎝0.5, 2.0⋅╲╱ [ReLU(P1)] ⋅ℯ   ⎠"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_model.get_expression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is expressed in terms of the following linear combinations of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 =  -1.27314538200194*X1 - 0.131854179607333*X10 - 0.679288735342555*X11 - 1.37590385443587*X12 - 1.20825766105207*X13 + 0.147945733672881*X14 + 0.512279699480107*X15 + 0.514298999505196*X16 - 0.665324759911238*X17 + 0.570333299643507*X18 - 1.25901020928724*X19 - 1.04514112522019*X2 + 0.177522171091293*X20 - 0.370458593221095*X21 + 0.955359316523103*X22 - 1.6111040771746*X23 + 1.32120418948573*X24 + 0.150838497061891*X25 - 1.09991320525515*X26 + 0.507018330862908*X27 - 0.718711608692359*X28 + 0.696644653939947*X29 + 1.67645724057484*X3 + 0.197346190253277*X30 - 0.259065810421908*X4 - 0.00640414241218379*X5 - 0.132460632585367*X6 - 0.592390875522769*X7 - 0.632141073153718*X8 + 1.17605718417642*X9\n"
     ]
    }
   ],
   "source": [
    "symbolic_model.print_projections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2480681/AD298KCW": {
     "DOI": "10.1109/T-C.1974.224051",
     "abstract": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples. The algorithm seeks to find one-and two-dimensional linear projections of multivariate data that are relatively highly revealing.",
     "author": [
      {
       "family": "Friedman",
       "given": "J.H."
      },
      {
       "family": "Tukey",
       "given": "J.W."
      }
     ],
     "container-title": "IEEE Transactions on Computers",
     "id": "2480681/AD298KCW",
     "issue": "9",
     "issued": {
      "month": 9,
      "year": 1974
     },
     "note": "Conference Name: IEEE Transactions on Computers",
     "page": "881-890",
     "page-first": "881",
     "title": "A Projection Pursuit Algorithm for Exploratory Data Analysis",
     "type": "article-journal",
     "volume": "C-23"
    },
    "2480681/H82VI2CA": {
     "URL": "http://arxiv.org/abs/1710.09412",
     "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.",
     "accessed": {
      "day": 16,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Zhang",
       "given": "Hongyi"
      },
      {
       "family": "Cisse",
       "given": "Moustapha"
      },
      {
       "family": "Dauphin",
       "given": "Yann N."
      },
      {
       "family": "Lopez-Paz",
       "given": "David"
      }
     ],
     "container-title": "arXiv:1710.09412 [cs, stat]",
     "id": "2480681/H82VI2CA",
     "issued": {
      "day": 27,
      "month": 4,
      "year": 2018
     },
     "note": "arXiv: 1710.09412",
     "shortTitle": "mixup",
     "title": "mixup: Beyond Empirical Risk Minimization",
     "title-short": "mixup",
     "type": "article-journal"
    },
    "2480681/IH83ZXGR": {
     "URL": "http://papers.nips.cc/paper/9308-demystifying-black-box-models-with-symbolic-metamodels.pdf",
     "author": [
      {
       "family": "Alaa",
       "given": "Ahmed M."
      },
      {
       "family": "van der Schaar",
       "given": "Mihaela"
      }
     ],
     "container-title": "Advances in Neural Information Processing Systems 32",
     "editor": [
      {
       "family": "Wallach",
       "given": "H."
      },
      {
       "family": "Larochelle",
       "given": "H."
      },
      {
       "family": "Beygelzimer",
       "given": "A."
      },
      {
       "family": "Alché-Buc",
       "given": "F. d\\textquotesingle"
      },
      {
       "family": "Fox",
       "given": "E."
      },
      {
       "family": "Garnett",
       "given": "R."
      }
     ],
     "id": "2480681/IH83ZXGR",
     "issued": {
      "year": 2019
     },
     "page": "11304–11314",
     "page-first": "11304",
     "publisher": "Curran Associates, Inc.",
     "title": "Demystifying Black-box Models with Symbolic Metamodels",
     "type": "chapter"
    },
    "2480681/M3SSP879": {
     "DOI": "10.1145/2939672.2939785",
     "ISBN": "978-1-4503-4232-2",
     "URL": "http://dl.acm.org/citation.cfm?doid=2939672.2939785",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Chen",
       "given": "Tianqi"
      },
      {
       "family": "Guestrin",
       "given": "Carlos"
      }
     ],
     "container-title": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '16",
     "event": "the 22nd ACM SIGKDD International Conference",
     "event-place": "San Francisco, California, USA",
     "id": "2480681/M3SSP879",
     "issued": {
      "year": 2016
     },
     "language": "en",
     "page": "785-794",
     "page-first": "785",
     "publisher": "ACM Press",
     "publisher-place": "San Francisco, California, USA",
     "shortTitle": "XGBoost",
     "title": "XGBoost: A Scalable Tree Boosting System",
     "title-short": "XGBoost",
     "type": "paper-conference"
    },
    "2480681/TI5B4V8W": {
     "URL": "http://archive.ics.uci.edu/ml",
     "author": [
      {
       "family": "Dua",
       "given": "Dheeru"
      },
      {
       "family": "Graff",
       "given": "Casey"
      }
     ],
     "id": "2480681/TI5B4V8W",
     "issued": {
      "year": 2017
     },
     "publisher": "University of California, Irvine, School of Information and Computer Sciences",
     "title": "UCI Machine Learning Repository",
     "type": "book"
    },
    "2480681/W63LCK3U": {
     "DOI": "10.1016/j.dss.2009.05.016",
     "URL": "https://linkinghub.elsevier.com/retrieve/pii/S0167923609001377",
     "accessed": {
      "day": 3,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Cortez",
       "given": "Paulo"
      },
      {
       "family": "Cerdeira",
       "given": "António"
      },
      {
       "family": "Almeida",
       "given": "Fernando"
      },
      {
       "family": "Matos",
       "given": "Telmo"
      },
      {
       "family": "Reis",
       "given": "José"
      }
     ],
     "container-title": "Decision Support Systems",
     "container-title-short": "Decision Support Systems",
     "id": "2480681/W63LCK3U",
     "issue": "4",
     "issued": {
      "year": 2009
     },
     "journalAbbreviation": "Decision Support Systems",
     "language": "en",
     "page": "547-553",
     "page-first": "547",
     "title": "Modeling wine preferences by data mining from physicochemical properties",
     "type": "article-journal",
     "volume": "47"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
